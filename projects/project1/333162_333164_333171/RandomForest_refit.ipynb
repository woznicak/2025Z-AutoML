{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cdfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9cd475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search - Loaded from files:\n",
      "  Bank: 0.1858421833675464\n",
      "  Gym: 0.1534136800030513\n",
      "  Heart Disease: 0.1277791441181989\n",
      "  Titanic: 0.1104537560930364\n"
     ]
    }
   ],
   "source": [
    "# Load Random Search results from best_models_summary.csv\n",
    "rs_best_models = pd.read_csv('RandomForestData/best_models_summary.csv')\n",
    "\n",
    "# Extract baseline brier scores (these are from RandomForest.ipynb baseline runs)\n",
    "baseline_brier_scores = [0.1892, 0.1819, 0.1067, 0.1520]  # Bank, Gym, Heart Disease, Titanic\n",
    "\n",
    "# Extract Random Search best parameters and test scores for each dataset\n",
    "import ast\n",
    "\n",
    "random_brier_adj = []\n",
    "random_best_params = []\n",
    "\n",
    "for dataset_name in ['Bank', 'Gym', 'Heart Disease', 'Titanic']:\n",
    "    row = rs_best_models[rs_best_models['dataset'] == dataset_name].iloc[0]\n",
    "    random_brier_adj.append(row['brier_score'])\n",
    "    random_best_params.append(ast.literal_eval(row['params']))\n",
    "\n",
    "print(\"Random Search - Loaded from files:\")\n",
    "for ds, brier in zip(['Bank', 'Gym', 'Heart Disease', 'Titanic'], random_brier_adj):\n",
    "    print(f\"  {ds}: {brier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce18aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bayesian Optimization - Loaded from files:\n",
      "  Bank: 0.1843225378562384\n",
      "  Gym: 0.1786213871377209\n",
      "  Heart Disease: 0.1044106469027575\n",
      "  Titanic: 0.1520592793866828\n"
     ]
    }
   ],
   "source": [
    "# Load Bayesian Optimization results from all_bayesian_results.csv\n",
    "bayes_results = pd.read_csv('RandomForestData/all_bayesian_results.csv')\n",
    "\n",
    "# Extract Bayesian best parameters and test scores for each dataset\n",
    "bayes_brier_adj = []\n",
    "bayes_best_params = []\n",
    "\n",
    "for dataset_name in ['Bank', 'Gym', 'Heart Disease', 'Titanic']:\n",
    "    # Filter for this dataset and completed trials\n",
    "    ds_trials = bayes_results[bayes_results['dataset'] == dataset_name]\n",
    "    ds_completed = ds_trials[ds_trials['state'] == 1]  # State 1 = COMPLETE\n",
    "    \n",
    "    # Get best trial (lowest brier_score)\n",
    "    best_trial = ds_completed.loc[ds_completed['brier_score'].idxmin()]\n",
    "    \n",
    "    # Extract test brier score (unique per dataset)\n",
    "    bayes_brier_adj.append(best_trial['test_brier_score'])\n",
    "    \n",
    "    # Extract parameters\n",
    "    params = {\n",
    "        'n_estimators': int(best_trial['n_estimators']),\n",
    "        'criterion': best_trial['criterion'],\n",
    "        'max_depth': None if pd.isna(best_trial['max_depth']) else int(best_trial['max_depth']),\n",
    "        'min_samples_split': int(best_trial['min_samples_split']),\n",
    "        'min_samples_leaf': int(best_trial['min_samples_leaf']),\n",
    "        'max_features': best_trial['max_features'] if best_trial['max_features'] == 'sqrt' else float(best_trial['max_features']),\n",
    "        'max_samples': None if pd.isna(best_trial['max_samples']) else float(best_trial['max_samples'])\n",
    "    }\n",
    "    bayes_best_params.append(params)\n",
    "\n",
    "print(\"\\nBayesian Optimization - Loaded from files:\")\n",
    "for ds, brier in zip(['Bank', 'Gym', 'Heart Disease', 'Titanic'], bayes_brier_adj):\n",
    "    print(f\"  {ds}: {brier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92dc120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Search dict created from files:\n",
      "  Datasets: ['bank', 'gym', 'heart', 'titanic']\n",
      "  Brier scores: [np.float64(0.1858421833675464), np.float64(0.1534136800030513), np.float64(0.1277791441181989), np.float64(0.1104537560930364)]\n"
     ]
    }
   ],
   "source": [
    "# Create random dict from loaded data\n",
    "random = {\n",
    "    'dataset': ['bank', 'gym', 'heart', 'titanic'],\n",
    "    'brier_adj': random_brier_adj,\n",
    "    'baseline_brier': baseline_brier_scores,\n",
    "    'best_params': random_best_params\n",
    "}\n",
    "\n",
    "print(\"\\nRandom Search dict created from files:\")\n",
    "print(f\"  Datasets: {random['dataset']}\")\n",
    "print(f\"  Brier scores: {random['brier_adj']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5bc215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bayesian Optimization dict created from files:\n",
      "  Datasets: ['bank', 'gym', 'heart', 'titanic']\n",
      "  Brier scores: [np.float64(0.1843225378562384), np.float64(0.1786213871377209), np.float64(0.1044106469027575), np.float64(0.1520592793866828)]\n"
     ]
    }
   ],
   "source": [
    "# Create bayes dict from loaded data\n",
    "bayes = {\n",
    "    'dataset': ['bank', 'gym', 'heart', 'titanic'],\n",
    "    'brier_adj': bayes_brier_adj,\n",
    "    'baseline_brier': baseline_brier_scores,\n",
    "    'best_params': bayes_best_params\n",
    "}\n",
    "\n",
    "print(\"\\nBayesian Optimization dict created from files:\")\n",
    "print(f\"  Datasets: {bayes['dataset']}\")\n",
    "print(f\"  Brier scores: {bayes['brier_adj']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741bfed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_df = pd.DataFrame(bayes)\n",
    "random_df = pd.DataFrame(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6052bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"preprocessed_datasets/bank_data.csv\")\n",
    "y1 = pd.read_csv(\"preprocessed_datasets/bank_target.csv\").squeeze()\n",
    "X2 = pd.read_csv(\"preprocessed_datasets/gym_data.csv\")\n",
    "y2 = pd.read_csv(\"preprocessed_datasets/gym_target.csv\").squeeze()\n",
    "X3 = pd.read_csv(\"preprocessed_datasets/heartDisease_data.csv\")\n",
    "y3 = pd.read_csv(\"preprocessed_datasets/heartDisease_target.csv\").squeeze()\n",
    "X4 = pd.read_csv(\"preprocessed_datasets/titanic_data.csv\")\n",
    "y4 = pd.read_csv(\"preprocessed_datasets/titanic_target.csv\").squeeze()\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=42, stratify=y4)\n",
    "\n",
    "\n",
    "datasets = [(X1_train, X1_test, y1_train, y1_test),\n",
    "            (X2_train, X2_test, y2_train, y2_test),\n",
    "            (X3_train, X3_test, y3_train, y3_test),\n",
    "            (X4_train, X4_test, y4_train, y4_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e1dd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1216, 'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_samples': 0.9} \n",
      "\n",
      " {'criterion': 'log_loss', 'max_depth': None, 'max_features': 0.33, 'max_samples': None, 'min_samples_leaf': 5, 'min_samples_split': 8, 'n_estimators': 1319}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>brier_adj</th>\n",
       "      <th>baseline_brier</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.104411</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>{'n_estimators': 1449, 'criterion': 'entropy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>titanic</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heart</td>\n",
       "      <td>0.127779</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>titanic</td>\n",
       "      <td>0.152059</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>{'n_estimators': 1216, 'criterion': 'log_loss'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gym</td>\n",
       "      <td>0.153414</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_depth': None, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gym</td>\n",
       "      <td>0.178621</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>{'n_estimators': 412, 'criterion': 'log_loss',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bank</td>\n",
       "      <td>0.184323</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>{'n_estimators': 1375, 'criterion': 'entropy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bank</td>\n",
       "      <td>0.185842</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': None, 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  brier_adj  baseline_brier  \\\n",
       "0    heart   0.104411          0.1067   \n",
       "1  titanic   0.110454          0.1520   \n",
       "2    heart   0.127779          0.1067   \n",
       "3  titanic   0.152059          0.1520   \n",
       "4      gym   0.153414          0.1819   \n",
       "5      gym   0.178621          0.1819   \n",
       "6     bank   0.184323          0.1892   \n",
       "7     bank   0.185842          0.1892   \n",
       "\n",
       "                                         best_params  \n",
       "0  {'n_estimators': 1449, 'criterion': 'entropy',...  \n",
       "1  {'criterion': 'entropy', 'max_depth': None, 'm...  \n",
       "2  {'criterion': 'entropy', 'max_depth': 10, 'max...  \n",
       "3  {'n_estimators': 1216, 'criterion': 'log_loss'...  \n",
       "4  {'criterion': 'log_loss', 'max_depth': None, '...  \n",
       "5  {'n_estimators': 412, 'criterion': 'log_loss',...  \n",
       "6  {'n_estimators': 1375, 'criterion': 'entropy',...  \n",
       "7  {'criterion': 'entropy', 'max_depth': None, 'm...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([random_df, bayes_df])\n",
    "df = df.sort_values('brier_adj').reset_index(drop = True)\n",
    "print(df.loc[3]['best_params'], \"\\n\\n\", df.loc[4]['best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "896857df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.33</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1449</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>996</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators criterion max_depth  min_samples_split  min_samples_leaf  \\\n",
       "0          1375   entropy      None                 19                 2   \n",
       "1          1319  log_loss      None                  8                 5   \n",
       "2          1449   entropy      10.0                  2                 1   \n",
       "3           996   entropy      None                  3                 1   \n",
       "\n",
       "  max_features max_samples  \n",
       "0         0.25         0.9  \n",
       "1         0.33        None  \n",
       "2         0.25         0.9  \n",
       "3         sqrt        None  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wybierz najlepszy wiersz (najmniejszy brier_adj) dla każdego zbioru\n",
    "best_rows = df.loc[df.groupby(\"dataset\")[\"brier_adj\"].idxmin()].reset_index(drop=True)\n",
    "\n",
    "param_list = best_rows[\"best_params\"].tolist()\n",
    "param_df = pd.DataFrame(param_list)\n",
    "param_df = param_df.replace({np.nan: None})\n",
    "\n",
    "\n",
    "param_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a646c8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1347,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'criterion': 'entropy',\n",
       " 'max_samples': None,\n",
       " 'max_depth': None,\n",
       " 'max_features': 0.25}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# --- przygotowanie param_df ---\n",
    "param_df = param_df.copy().replace({np.nan: None})\n",
    "\n",
    "numeric_params = [\n",
    "    \"n_estimators\",\n",
    "    \"min_samples_split\",\n",
    "    \"min_samples_leaf\"\n",
    "]\n",
    "\n",
    "categorical_params = [\n",
    "    \"criterion\",\n",
    "    \"max_samples\",\n",
    "    \"max_depth\",\n",
    "    \"max_features\"\n",
    "]\n",
    "\n",
    "final_grid = {}\n",
    "\n",
    "# --- numeric: median ---\n",
    "for col in numeric_params:\n",
    "    final_grid[col] = int(pd.to_numeric(param_df[col], errors=\"coerce\").median())\n",
    "\n",
    "# --- categorical: mode z pełną obsługą None ---\n",
    "def mode_with_none(values):\n",
    "    \"\"\"mode obsługujący None jako wartość normalną\"\"\"\n",
    "    values_list = list(values)\n",
    "\n",
    "    # jeżeli wszystkie wartości są None → zwracamy None\n",
    "    if all(v is None for v in values_list):\n",
    "        return None\n",
    "\n",
    "    # Counter działa również z None\n",
    "    counts = Counter(values_list)\n",
    "    \n",
    "    # znajdź najlepszą wartość\n",
    "    most_common_value, _ = counts.most_common(1)[0]\n",
    "    return most_common_value\n",
    "\n",
    "\n",
    "for col in categorical_params:\n",
    "    final_grid[col] = mode_with_none(param_df[col])\n",
    "\n",
    "final_grid['max_samples'] = None\n",
    "\n",
    "final_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a157320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank data       | Brier: 0.186864 | Improvement: +0.002336 | Relative: +1.23%\n",
      "Gym data        | Brier: 0.178418 | Improvement: +0.003482 | Relative: +1.91%\n",
      "Heart disease   | Brier: 0.104385 | Improvement: +0.002315 | Relative: +2.17%\n",
      "Titanic         | Brier: 0.151285 | Improvement: +0.000715 | Relative: +0.47%\n",
      "\n",
      "\n",
      "--- LATEX TABLE VALUES ---\n",
      "Bank data & $+0.0023$ & $+1.2%$ \\\\\n",
      "Gym data & $+0.0035$ & $+1.9%$ \\\\\n",
      "Heart disease & $+0.0023$ & $+2.2%$ \\\\\n",
      "Titanic & $+0.0007$ & $+0.5%$ \\\\\n",
      "mean and std\n",
      "0.00221215876780299       0.0009847874452360336\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Baseline Brier scores for datasets:\n",
    "# Bank, Gym, Heart, Titanic\n",
    "baseline_brier_scores = np.array([0.1892, 0.1819, 0.1067, 0.1520])\n",
    "\n",
    "# Results will be stored here\n",
    "rf_brier = []\n",
    "rf_improvement = []\n",
    "rf_relative = []\n",
    "\n",
    "dataset_names = [\"Bank data\", \"Gym data\", \"Heart disease\", \"Titanic\"]\n",
    "\n",
    "for i in range(4):    \n",
    "    model = RandomForestClassifier(**final_grid, random_state=42, n_jobs=-1)\n",
    "    model.fit(datasets[i][0], datasets[i][2])\n",
    "\n",
    "    brier = brier_score_loss(datasets[i][3], model.predict_proba(datasets[i][1])[:, 1])\n",
    "    rf_brier.append(brier)\n",
    "\n",
    "    improvement = baseline_brier_scores[i] - brier\n",
    "    relative = improvement / baseline_brier_scores[i]\n",
    "\n",
    "    rf_improvement.append(improvement)\n",
    "    rf_relative.append(relative)\n",
    "\n",
    "    print(f\"{dataset_names[i]:<15} | Brier: {brier:.6f} | \"\n",
    "          f\"Improvement: {improvement:+.6f} | Relative: {relative:+.2%}\")\n",
    "\n",
    "print(\"\\n\\n--- LATEX TABLE VALUES ---\")\n",
    "for name, imp, rel in zip(dataset_names, rf_improvement, rf_relative):\n",
    "    print(f\"{name} & ${imp:+.4f}$ & ${rel:+.1%}$ \\\\\\\\\")\n",
    "\n",
    "print(\"mean and std\")\n",
    "print(np.mean(rf_improvement), \"     \", np.std(rf_improvement))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
